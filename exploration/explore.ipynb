{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "647fab26",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1.2.0\n"
                    ]
                }
            ],
            "source": [
                "import langchain\n",
                "print(langchain.__version__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "a85299c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_community.utilities import SerpAPIWrapper\n",
                "from langchain_community.document_loaders import WebBaseLoader\n",
                "import dotenv\n",
                "from dotenv import load_dotenv\n",
                "import os\n",
                "from langchain_core.tools import tool,Tool\n",
                "from langchain.agents import create_agent\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "# Import FakeListLLM for testing\n",
                "from langchain_community.llms import FakeListLLM\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "e5af3ec4",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv()\n",
                "serp_api_key=os.getenv(\"SERP_API_KEY\")\n",
                "google_api_key=os.getenv(\"GOOGLE_API_KEY\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "63902b54",
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt='''You are an expert educator and quiz master for advanced technical students.\n",
                "Your goal is to create a quiz based strictly on the following text context.\n",
                "Text Context:   \"{text}\"\n",
                "\n",
                "Instructions to be followed:\n",
                "1. Create {num_questions} multiple-choice questions(MCQs) based only on the Text above\"\n",
                "2. For each question, provide 4 options (A, B, C, D)\n",
                "3. Identfiy the correct answer\n",
                "4. Ensure the questions test understanding, not just simple words matching.\n",
                "5. Difficulty level : {difficulty} (eg. easy,medium or hard)\n",
                "\n",
                "Output Format: \n",
                "You must output a strictly valid JSON string. Do not output markdown code blocks.\n",
                "The JSON format must be list of objects like this: \n",
                "[\n",
                "    {{\n",
                "        \"question\": \"The question text here?\",\n",
                "        \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n",
                "        \"correct_answer\": \"Option B\",\n",
                "        \"explanation\": \"A brief explanation of why B is correct.\"\n",
                "    }}\n",
                "]\n",
                "'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "212bf779",
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_template=PromptTemplate(input_variables=[\"text\",\"num_questions\",\"difficulty\"],template=prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "5562a160",
            "metadata": {},
            "outputs": [],
            "source": [
                "final_prompt=(prompt_template.format(text='''International Debut: He made his ODI debut for India on August 18, 2008, against Sri Lanka.\n",
                "World Cup Success: Kohli was a key member of the Indian team that won the 2011 ODI World Cup, the 2013 ICC Champions Trophy, and the 2024 T20 World Cup.\n",
                "Most ODI Centuries: He holds the world record for the most centuries in One Day Internationals (ODIs), surpassing Sachin Tendulkar's long-standing record with his 50th ODI century during the 2023 World Cup.\n",
                "Record Run Scorer: He is the fastest batsman to reach multiple thousand-run milestones in ODIs, including 8,000, 10,000, 12,000, and 14,000 runs.\n",
                "Successful Test Captain: As India's most successful Test captain, he led the team to a historic Test series win in Australia in 2018-19 and helped them maintain the #1 Test ranking for a long period.\n",
                "ICC Awards: His numerous accolades include the Sir Garfield Sobers Trophy (ICC Cricketer of the Year) in 2017 and 2018, and the ICC Men's ODI Cricketer of the Decade (2011â€“2020).\n",
                "IPL Career: In the Indian Premier League (IPL), he has played exclusively for the Royal Challengers Bengaluru (RCB) since 2008 and led them to their first title in the 2025 season.\n",
                "Retirement Announcements: Kohli retired from T20 International cricket in 2024 after India's T20 World Cup victory and announced his retirement from Test cricket in May 2025.\n",
                "Personal Life: He is married to popular Bollywood actress Anushka Sharma, and they have two children together, a daughter named Vamika and a son named Akaay.\n",
                "Off-Field Influence: Known for his discipline and passion, he is a role model for aspiring athletes and a highly influential global figure with a significant net worth from endorsements and business ventures.'''\n",
                ", num_questions=10,difficulty='easy'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "29fd8cd1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using FAKE LLM for testing...\n",
                        "\n",
                        "[\n",
                        "    {\n",
                        "        \"question\": \"Who holds the record for the most ODI centuries?\",\n",
                        "        \"options\": [\"Sachin Tendulkar\", \"Virat Kohli\", \"Ricky Ponting\", \"Rohit Sharma\"],\n",
                        "        \"correct_answer\": \"Virat Kohli\",\n",
                        "        \"explanation\": \"Virat Kohli surpassed Sachin Tendulkar's record with his 50th ODI century during the 2023 World Cup.\"\n",
                        "    },\n",
                        "    {\n",
                        "        \"question\": \"Which IPL team has Virat Kohli played for exclusively since 2008?\",\n",
                        "        \"options\": [\"Mumbai Indians\", \"Chennai Super Kings\", \"Royal Challengers Bengaluru\", \"Kolkata Knight Riders\"],\n",
                        "        \"correct_answer\": \"Royal Challengers Bengaluru\",\n",
                        "        \"explanation\": \"He has played exclusively for RCB since the inception of the IPL in 2008.\"\n",
                        "    }\n",
                        "]\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# MOCK (DUMMY) IMPLEMENTATION\n",
                "# This replaces the real Gemini call with a fake one to save API credits during testing.\n",
                "\n",
                "USE_MOCK = True\n",
                "\n",
                "dummy_response_json = \"\"\"\n",
                "[\n",
                "    {\n",
                "        \"question\": \"Who holds the record for the most ODI centuries?\",\n",
                "        \"options\": [\"Sachin Tendulkar\", \"Virat Kohli\", \"Ricky Ponting\", \"Rohit Sharma\"],\n",
                "        \"correct_answer\": \"Virat Kohli\",\n",
                "        \"explanation\": \"Virat Kohli surpassed Sachin Tendulkar's record with his 50th ODI century during the 2023 World Cup.\"\n",
                "    },\n",
                "    {\n",
                "        \"question\": \"Which IPL team has Virat Kohli played for exclusively since 2008?\",\n",
                "        \"options\": [\"Mumbai Indians\", \"Chennai Super Kings\", \"Royal Challengers Bengaluru\", \"Kolkata Knight Riders\"],\n",
                "        \"correct_answer\": \"Royal Challengers Bengaluru\",\n",
                "        \"explanation\": \"He has played exclusively for RCB since the inception of the IPL in 2008.\"\n",
                "    }\n",
                "]\n",
                "\"\"\"\n",
                "\n",
                "if USE_MOCK:\n",
                "    print(\"Using FAKE LLM for testing...\")\n",
                "    # FakeListLLM expects a list of responses to cycle through\n",
                "    client = FakeListLLM(responses=[dummy_response_json])\n",
                "    response = client.invoke(final_prompt) \n",
                "    # Note: FakeListLLM returns string directly in some versions, or object in others. \n",
                "    # Invoke typically returns a string for legacy LLMs or BaseMessage for ChatModels.\n",
                "    # Let's handle both just in case.\n",
                "    if hasattr(response, 'content'):\n",
                "        print(response.content)\n",
                "    else:\n",
                "        print(response)\n",
                "else:\n",
                "    print(\"Using REAL Gemini LLM...\")\n",
                "    client = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
                "    response = client.invoke(final_prompt)\n",
                "    print(response.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "6a427998",
            "metadata": {},
            "outputs": [],
            "source": [
                "messages=client.invoke(prompt.format(text='Hello sir how are you',num_questions=2,difficulty='easy'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "e799566e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[\n",
                        "    {\n",
                        "        \"question\": \"Who holds the record for the most ODI centuries?\",\n",
                        "        \"options\": [\"Sachin Tendulkar\", \"Virat Kohli\", \"Ricky Ponting\", \"Rohit Sharma\"],\n",
                        "        \"correct_answer\": \"Virat Kohli\",\n",
                        "        \"explanation\": \"Virat Kohli surpassed Sachin Tendulkar's record with his 50th ODI century during the 2023 World Cup.\"\n",
                        "    },\n",
                        "    {\n",
                        "        \"question\": \"Which IPL team has Virat Kohli played for exclusively since 2008?\",\n",
                        "        \"options\": [\"Mumbai Indians\", \"Chennai Super Kings\", \"Royal Challengers Bengaluru\", \"Kolkata Knight Riders\"],\n",
                        "        \"correct_answer\": \"Royal Challengers Bengaluru\",\n",
                        "        \"explanation\": \"He has played exclusively for RCB since the inception of the IPL in 2008.\"\n",
                        "    }\n",
                        "]\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(messages)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "b9ff7bd2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "AI-Powered Document Search & Question Answering (RAG System)\n",
                        "Purpose & Vision\n",
                        "This project aims to develop an AI-powered system that enables users to upload, search, and\n",
                        "query documents with intelligent, context-aware responses. The system integrates Retrieval-\n",
                        "Augmented Generation (RAG) with Google Gemini, combining local vector search with a generative\n",
                        "language model to produce accurate and grounded answers.\n",
                        "Core Concept: Retrieval-Augmented Generation (RAG)\n",
                        "Retrieval-Augmented Generation (RAG) bridges the gap between retrieval-based search and\n",
                        "generative AI. It retrieves the most relevant document chunks through vector similarity search\n",
                        "and feeds them to a large language model (LLM), ensuring responses are contextually accurate,\n",
                        "citeable, and based on real data rather than hallucinations. This creates a balance between\n",
                        "factual precision and generative reasoning.\n",
                        "System Architecture\n",
                        "1. Document ingestion: Users can upload PDF, DOCX, TXT, or provide URLs.\n",
                        "2. Text extraction: Raw text and metadata are extracted using PyMuPDF, python-docx, and\n",
                        "BeautifulSoup.\n",
                        "3. Chunking: Text is divided into overlapping, token-aware chunks to preserve continuity.\n",
                        "4. Embeddings: Each chunk is embedded using Sentence-Transformers, producing vector\n",
                        "representations.\n",
                        "5. Vector Store: FAISS is used to store and query embeddings efficiently.\n",
                        "6. Retrieval: On user queries, relevant chunks are retrieved using similarity search.\n",
                        "7. Generation: Gemini 2.5 models generate responses based solely on retrieved context.\n",
                        "Key Components & Workflow\n",
                        " Streamlit UI: Provides an intuitive interface for document uploads, queries, and answer\n",
                        "display.\n",
                        " Ingestion Pipeline: Handles text extraction, chunking, and metadata creation.\n",
                        " Embeddings & Vector Search: Uses local sentence-transformers and FAISS for similarity\n",
                        "retrieval.\n",
                        " RAG Core: Retrieves top-k relevant chunks and prompts Gemini with strict context prompts.\n",
                        " Models: Gemini 2.5 Pro for advanced reasoning; Gemini 2.5 Flash for faster responses.\n",
                        " Storage: Chunks, embeddings, and metadata stored locally for reproducibility.\n",
                        "Technologies Used\n",
                        " Python, Streamlit for frontend and orchestration.\n",
                        " FAISS for efficient vector similarity search.\n",
                        " Sentence-Transformers for embedding generation.\n",
                        " Google Generative AI (Gemini) for contextual understanding and natural language responses.\n",
                        " tiktoken for token-aware chunking.\n",
                        " python-docx, PyMuPDF, BeautifulSoup for content parsing.\n",
                        "Implementation Details\n",
                        " Embeddings are computed locally using sentence-transformers/all-MiniLM-L6-v2.\n",
                        " Gemini 2.5 models (Pro or Flash) are accessed via the Google Generative AI API.\n",
                        " API key management handled via .env file for security.\n",
                        " FAISS index and metadata persist locally for fast access and reduced API dependency.\n",
                        "Security & Reliability\n",
                        " API key stored securely in .env, never exposed in the UI.\n",
                        " All documents and embeddings processed locally; no third-party uploads.\n",
                        " Fallback systems for missing dependencies or tokenizer errors.\n",
                        " Context-restricted prompting minimizes hallucinations and ensures grounded answers.\n",
                        "Limitations & Future Enhancements\n",
                        " CPU-only embedding may slow down large-scale indexing.\n",
                        " Long documents may require optimized chunk batching.\n",
                        " Planned upgrades include Gemini embeddings, cross-encoder re-ranking, and multi-file citation\n",
                        "mapping.\n",
                        " Potential future extensions include document summarization dashboards and interactive\n",
                        "analytics.\n",
                        "How to Run the Project\n",
                        "1. Add your Gemini API key in .env as GOOGLE_API_KEY.\n",
                        "2. Install dependencies: pip install -r requirements.txt\n",
                        "3. Run Streamlit: streamlit run app.py\n",
                        "4. Upload documents or URLs, initialize indexing, and ask contextual questions.\n",
                        "Conceptual Insight\n",
                        "This system represents a hybrid of retrieval and reasoning, embodying the next generation of\n",
                        "intelligent document understanding. By uniting semantic search with LLM-based contextual\n",
                        "reasoning, it demonstrates how enterprise and research workflows can leverage AI for faster,\n",
                        "explainable knowledge discovery.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "\n",
                "loader=PyPDFLoader(r\"C:\\ALL PROJECTS\\BrainBolt\\data\\pdfs\\AI_Powered_Document_Search_RAG_Overview.pdf\")\n",
                "pages=loader.load()\n",
                "full_text=\"\\n\".join([page.page_content for page in pages])\n",
                "print(full_text)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "803d168d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "print(os.path.isfile(\"C:\\ALL PROJECTS\\BrainBolt\\data\\pdfs\\AI_Powered_Document_Search_RAG_Overview.pdf\"))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "38c0f3e4",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
